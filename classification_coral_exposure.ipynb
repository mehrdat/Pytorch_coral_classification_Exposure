{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler,LabelEncoder\n",
    "\n",
    "import torch.nn.functional as F # Sets of functions such as ReLU\n",
    "from torchvision import datasets, transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cyclone_Frequency</th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>ClimSST</th>\n",
       "      <th>Ocean_Name</th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Distance_to_Shore</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Date_Year</th>\n",
       "      <th>Bleaching_Level</th>\n",
       "      <th>Temperature_Maximum</th>\n",
       "      <th>SSTA</th>\n",
       "      <th>TSA</th>\n",
       "      <th>Percent_Bleaching</th>\n",
       "      <th>Temperature_Mean</th>\n",
       "      <th>Realm_Name</th>\n",
       "      <th>Percent_Cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34510</th>\n",
       "      <td>85.57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300.97</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>United States</td>\n",
       "      <td>49.16</td>\n",
       "      <td>Sheltered</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>2005</td>\n",
       "      <td>Population</td>\n",
       "      <td>303.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.34</td>\n",
       "      <td>Tropical Atlantic</td>\n",
       "      <td>28.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34511</th>\n",
       "      <td>85.57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300.97</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>United States</td>\n",
       "      <td>49.16</td>\n",
       "      <td>Sheltered</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>2005</td>\n",
       "      <td>Population</td>\n",
       "      <td>303.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.34</td>\n",
       "      <td>Tropical Atlantic</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34512</th>\n",
       "      <td>35.71</td>\n",
       "      <td>14.0</td>\n",
       "      <td>301.58</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>8768.03</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>2016</td>\n",
       "      <td>Colony</td>\n",
       "      <td>305.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>100.0</td>\n",
       "      <td>301.26</td>\n",
       "      <td>Western Indo-Pacific</td>\n",
       "      <td>19.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34513</th>\n",
       "      <td>58.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>299.79</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>United States</td>\n",
       "      <td>8170.00</td>\n",
       "      <td>Exposed</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>2015</td>\n",
       "      <td>Colony</td>\n",
       "      <td>306.04</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.91</td>\n",
       "      <td>100.0</td>\n",
       "      <td>299.79</td>\n",
       "      <td>Tropical Atlantic</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34514</th>\n",
       "      <td>62.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>298.32</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>United States</td>\n",
       "      <td>1863.00</td>\n",
       "      <td>Sheltered</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>2015</td>\n",
       "      <td>Colony</td>\n",
       "      <td>306.82</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>100.0</td>\n",
       "      <td>299.65</td>\n",
       "      <td>Tropical Atlantic</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cyclone_Frequency  Depth_m  ClimSST Ocean_Name   Country_Name  \\\n",
       "34510              85.57      3.0   300.97   Atlantic  United States   \n",
       "34511              85.57      3.0   300.97   Atlantic  United States   \n",
       "34512              35.71     14.0   301.58     Indian     Madagascar   \n",
       "34513              58.42      4.0   299.79   Atlantic  United States   \n",
       "34514              62.54      4.0   298.32   Atlantic  United States   \n",
       "\n",
       "       Distance_to_Shore   Exposure  Turbidity  Date_Year Bleaching_Level  \\\n",
       "34510              49.16  Sheltered     0.0586       2005      Population   \n",
       "34511              49.16  Sheltered     0.0586       2005      Population   \n",
       "34512            8768.03  Sometimes     0.0628       2016          Colony   \n",
       "34513            8170.00    Exposed     0.1203       2015          Colony   \n",
       "34514            1863.00  Sheltered     0.1703       2015          Colony   \n",
       "\n",
       "       Temperature_Maximum  SSTA   TSA  Percent_Bleaching  Temperature_Mean  \\\n",
       "34510               303.67  0.32  0.21              100.0            300.34   \n",
       "34511               303.67  0.32  0.21              100.0            300.34   \n",
       "34512               305.32  0.63  0.59              100.0            301.26   \n",
       "34513               306.04  3.91  3.91              100.0            299.79   \n",
       "34514               306.82  1.59 -0.57              100.0            299.65   \n",
       "\n",
       "                 Realm_Name  Percent_Cover  \n",
       "34510     Tropical Atlantic          28.75  \n",
       "34511     Tropical Atlantic           5.62  \n",
       "34512  Western Indo-Pacific          19.06  \n",
       "34513     Tropical Atlantic          12.50  \n",
       "34514     Tropical Atlantic          12.50  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coral=pd.read_csv('./coral_cleaned.csv')\n",
    "coral=coral.drop('Sample_ID', axis=1)\n",
    "#coral=coral.set_index('Date_Year')\n",
    "coral.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34515 entries, 0 to 34514\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Cyclone_Frequency    34515 non-null  float64\n",
      " 1   Depth_m              34515 non-null  float64\n",
      " 2   ClimSST              34515 non-null  float64\n",
      " 3   Ocean_Name           34515 non-null  object \n",
      " 4   Country_Name         34515 non-null  object \n",
      " 5   Distance_to_Shore    34515 non-null  float64\n",
      " 6   Exposure             34515 non-null  object \n",
      " 7   Turbidity            34515 non-null  float64\n",
      " 8   Date_Year            34515 non-null  int64  \n",
      " 9   Bleaching_Level      34515 non-null  object \n",
      " 10  Temperature_Maximum  34515 non-null  float64\n",
      " 11  SSTA                 34515 non-null  float64\n",
      " 12  TSA                  34515 non-null  float64\n",
      " 13  Percent_Bleaching    34515 non-null  float64\n",
      " 14  Temperature_Mean     34515 non-null  float64\n",
      " 15  Realm_Name           34515 non-null  object \n",
      " 16  Percent_Cover        34515 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(5)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "coral.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exposure\n",
       "Sheltered    19504\n",
       "Exposed      12237\n",
       "Sometimes     2774\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coral['Exposure'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cyclone_Frequency      0\n",
       "Depth_m                0\n",
       "ClimSST                0\n",
       "Ocean_Name             0\n",
       "Country_Name           0\n",
       "Distance_to_Shore      0\n",
       "Exposure               0\n",
       "Turbidity              0\n",
       "Date_Year              0\n",
       "Bleaching_Level        0\n",
       "Temperature_Maximum    0\n",
       "SSTA                   0\n",
       "TSA                    0\n",
       "Percent_Bleaching      0\n",
       "Temperature_Mean       0\n",
       "Realm_Name             0\n",
       "Percent_Cover          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "def Knn_impute(df):\n",
    "    knn_imputer = KNNImputer(n_neighbors=2)\n",
    "    coral_numeric = df.copy()\n",
    "    for column in coral_numeric.select_dtypes(include=['object']).columns:\n",
    "        coral_numeric[column] = coral_numeric[column].astype('category').cat.codes\n",
    "    #coral_numeric['Exposure'] = coral_numeric['Exposure'].astype('category').cat.codes\n",
    "    coral_imputed = knn_imputer.fit_transform(coral_numeric)\n",
    "    \n",
    "    coral_imputed = pd.DataFrame(coral_imputed, columns=coral.columns)\n",
    "    coral_imputed['Exposure'] = pd.Categorical.from_codes(coral_imputed['Exposure'].astype(int), coral['Exposure'].astype('category').cat.categories)\n",
    "\n",
    "    return coral_imputed  \n",
    "\n",
    "coral_imputed=Knn_impute(coral)\n",
    "coral.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cyclone_Frequency</th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>ClimSST</th>\n",
       "      <th>Distance_to_Shore</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Date_Year</th>\n",
       "      <th>Temperature_Maximum</th>\n",
       "      <th>SSTA</th>\n",
       "      <th>TSA</th>\n",
       "      <th>Percent_Bleaching</th>\n",
       "      <th>Temperature_Mean</th>\n",
       "      <th>Percent_Cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "      <td>34515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.325062</td>\n",
       "      <td>7.001455</td>\n",
       "      <td>294.191764</td>\n",
       "      <td>3671.828392</td>\n",
       "      <td>0.075548</td>\n",
       "      <td>2008.837317</td>\n",
       "      <td>305.133870</td>\n",
       "      <td>0.279616</td>\n",
       "      <td>-0.960571</td>\n",
       "      <td>9.619465</td>\n",
       "      <td>300.418421</td>\n",
       "      <td>17.212724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.597484</td>\n",
       "      <td>4.135800</td>\n",
       "      <td>14.777580</td>\n",
       "      <td>13384.132023</td>\n",
       "      <td>0.061992</td>\n",
       "      <td>5.719490</td>\n",
       "      <td>1.301263</td>\n",
       "      <td>0.829914</td>\n",
       "      <td>1.645223</td>\n",
       "      <td>20.190956</td>\n",
       "      <td>1.560122</td>\n",
       "      <td>17.373931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.150000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>300.130000</td>\n",
       "      <td>-4.260000</td>\n",
       "      <td>-11.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.880000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.940000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>298.580000</td>\n",
       "      <td>126.240000</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>304.420000</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>-1.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>299.770000</td>\n",
       "      <td>5.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51.380000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>476.030000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>305.100000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>300.780000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.060000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>301.990000</td>\n",
       "      <td>1836.530000</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>305.780000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>301.585000</td>\n",
       "      <td>21.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105.800000</td>\n",
       "      <td>50.300000</td>\n",
       "      <td>307.220000</td>\n",
       "      <td>299218.500000</td>\n",
       "      <td>1.284500</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>313.140000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>303.520000</td>\n",
       "      <td>98.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cyclone_Frequency       Depth_m       ClimSST  Distance_to_Shore  \\\n",
       "count       34515.000000  34515.000000  34515.000000       34515.000000   \n",
       "mean           52.325062      7.001455    294.191764        3671.828392   \n",
       "std             7.597484      4.135800     14.777580       13384.132023   \n",
       "min            18.310000      0.000000    262.150000           3.200000   \n",
       "25%            47.940000      4.000000    298.580000         126.240000   \n",
       "50%            51.380000      6.000000    300.800000         476.030000   \n",
       "75%            56.060000     10.000000    301.990000        1836.530000   \n",
       "max           105.800000     50.300000    307.220000      299218.500000   \n",
       "\n",
       "          Turbidity     Date_Year  Temperature_Maximum          SSTA  \\\n",
       "count  34515.000000  34515.000000         34515.000000  34515.000000   \n",
       "mean       0.075548   2008.837317           305.133870      0.279616   \n",
       "std        0.061992      5.719490             1.301263      0.829914   \n",
       "min        0.000000   1980.000000           300.130000     -4.260000   \n",
       "25%        0.039600   2005.000000           304.420000     -0.210000   \n",
       "50%        0.057000   2008.000000           305.100000      0.260000   \n",
       "75%        0.084200   2014.000000           305.780000      0.770000   \n",
       "max        1.284500   2020.000000           313.140000      5.900000   \n",
       "\n",
       "                TSA  Percent_Bleaching  Temperature_Mean  Percent_Cover  \n",
       "count  34515.000000       34515.000000      34515.000000   34515.000000  \n",
       "mean      -0.960571           9.619465        300.418421      17.212724  \n",
       "std        1.645223          20.190956          1.560122      17.373931  \n",
       "min      -11.970000           0.000000        290.880000       0.000000  \n",
       "25%       -1.810000           0.000000        299.770000       5.620000  \n",
       "50%       -0.710000           0.250000        300.780000      12.500000  \n",
       "75%        0.120000           6.000000        301.585000      21.250000  \n",
       "max        5.900000         100.000000        303.520000      98.750000  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.get_dummies(coral['Coral'], drop_first=True)\n",
    "#coral_cleaned=coral[coral['Percent_Cover']!=0]\n",
    "\n",
    "#iterative_imputer = IterativeImputer()\n",
    "#coral_cleaned=iterative_imputer.fit_transform(coral)\n",
    "coral_cleaned=coral.copy()\n",
    "coral_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "coral_cleaned.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of coral_hoted: (34515, 452)\n"
     ]
    }
   ],
   "source": [
    "get_dummies_columns=[\"Ocean_Name\", \"Country_Name\", \"Percent_Cover\", \"Bleaching_Level\", \"Realm_Name\"]\n",
    "#pd.get_dummies(coral_cleaned['Coral'], drop_first=True)\n",
    "hot_encoder=OneHotEncoder(sparse_output=False)\n",
    "coral_hoted=hot_encoder.fit_transform(coral_cleaned[get_dummies_columns])\n",
    "\n",
    "print(\"Shape of coral_hoted:\", coral_hoted.shape)\n",
    "encoded_feature_names = hot_encoder.get_feature_names_out(get_dummies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34515, 452)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Exposure\n",
       "1    19504\n",
       "0    12237\n",
       "2     2774\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if coral_hoted.shape[1] == len(encoded_feature_names):\n",
    "    # Convert the encoded data to a DataFrame\n",
    "    encoded_df = pd.DataFrame(coral_hoted, columns=encoded_feature_names)\n",
    "    print(encoded_df.shape)\n",
    "else:\n",
    "    print(\"Mismatch between the shape of encoded data and the number of feature names.\")\n",
    "\n",
    "\n",
    "df_without_get_dummies = coral_cleaned.drop(columns=get_dummies_columns)\n",
    "\n",
    "df_concatenated=pd.concat([df_without_get_dummies, encoded_df], axis=1)\n",
    "df_concatenated.shape\n",
    "\n",
    "exp_less=df_concatenated.drop('Exposure', axis=1)\n",
    "le=LabelEncoder()\n",
    "df_concatenated['Exposure']=le.fit_transform(df_concatenated['Exposure'])\n",
    "\n",
    "df_concatenated['Exposure'].value_counts()\n",
    "#le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cyclone_Frequency</th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>ClimSST</th>\n",
       "      <th>Distance_to_Shore</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Date_Year</th>\n",
       "      <th>Temperature_Maximum</th>\n",
       "      <th>SSTA</th>\n",
       "      <th>TSA</th>\n",
       "      <th>Percent_Bleaching</th>\n",
       "      <th>...</th>\n",
       "      <th>Bleaching_Level_Population</th>\n",
       "      <th>Realm_Name_Central Indo-Pacific</th>\n",
       "      <th>Realm_Name_Eastern Indo-Pacific</th>\n",
       "      <th>Realm_Name_Temperate Australasia</th>\n",
       "      <th>Realm_Name_Temperate Northern Atlantic</th>\n",
       "      <th>Realm_Name_Temperate Northern Pacific</th>\n",
       "      <th>Realm_Name_Tropical Atlantic</th>\n",
       "      <th>Realm_Name_Tropical Eastern Pacific</th>\n",
       "      <th>Realm_Name_Western Indo-Pacific</th>\n",
       "      <th>Exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361070</td>\n",
       "      <td>0.198807</td>\n",
       "      <td>0.875527</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.374016</td>\n",
       "      <td>0.625070</td>\n",
       "      <td>0.502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375929</td>\n",
       "      <td>0.278330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.375096</td>\n",
       "      <td>0.546260</td>\n",
       "      <td>0.742026</td>\n",
       "      <td>0.507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493885</td>\n",
       "      <td>0.139165</td>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.308224</td>\n",
       "      <td>0.423228</td>\n",
       "      <td>0.522104</td>\n",
       "      <td>0.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.538119</td>\n",
       "      <td>0.179324</td>\n",
       "      <td>0.843355</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.302844</td>\n",
       "      <td>0.412402</td>\n",
       "      <td>0.542809</td>\n",
       "      <td>0.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.538119</td>\n",
       "      <td>0.248509</td>\n",
       "      <td>0.843133</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.279016</td>\n",
       "      <td>0.419291</td>\n",
       "      <td>0.547286</td>\n",
       "      <td>0.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34510</th>\n",
       "      <td>0.768774</td>\n",
       "      <td>0.059642</td>\n",
       "      <td>0.861327</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.045621</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.272098</td>\n",
       "      <td>0.450787</td>\n",
       "      <td>0.681589</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34511</th>\n",
       "      <td>0.768774</td>\n",
       "      <td>0.059642</td>\n",
       "      <td>0.861327</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.045621</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.272098</td>\n",
       "      <td>0.450787</td>\n",
       "      <td>0.681589</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34512</th>\n",
       "      <td>0.198880</td>\n",
       "      <td>0.278330</td>\n",
       "      <td>0.874861</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.048891</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.398924</td>\n",
       "      <td>0.481299</td>\n",
       "      <td>0.702854</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34513</th>\n",
       "      <td>0.458452</td>\n",
       "      <td>0.079523</td>\n",
       "      <td>0.835145</td>\n",
       "      <td>0.027294</td>\n",
       "      <td>0.093655</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.454266</td>\n",
       "      <td>0.804134</td>\n",
       "      <td>0.888640</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34514</th>\n",
       "      <td>0.505543</td>\n",
       "      <td>0.079523</td>\n",
       "      <td>0.802529</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.132581</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.514220</td>\n",
       "      <td>0.575787</td>\n",
       "      <td>0.637941</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34515 rows × 464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cyclone_Frequency   Depth_m   ClimSST  Distance_to_Shore  Turbidity  \\\n",
       "0               0.361070  0.198807  0.875527           0.028461   0.022343   \n",
       "1               0.375929  0.278330  0.000000           0.004774   0.020397   \n",
       "2               0.493885  0.139165  0.812958           0.000599   0.033398   \n",
       "3               0.538119  0.179324  0.843355           0.001036   0.033009   \n",
       "4               0.538119  0.248509  0.843133           0.002636   0.033009   \n",
       "...                  ...       ...       ...                ...        ...   \n",
       "34510           0.768774  0.059642  0.861327           0.000154   0.045621   \n",
       "34511           0.768774  0.059642  0.861327           0.000154   0.045621   \n",
       "34512           0.198880  0.278330  0.874861           0.029293   0.048891   \n",
       "34513           0.458452  0.079523  0.835145           0.027294   0.093655   \n",
       "34514           0.505543  0.079523  0.802529           0.006216   0.132581   \n",
       "\n",
       "       Date_Year  Temperature_Maximum      SSTA       TSA  Percent_Bleaching  \\\n",
       "0          0.625             0.350500  0.374016  0.625070              0.502   \n",
       "1          0.275             0.375096  0.546260  0.742026              0.507   \n",
       "2          0.650             0.308224  0.423228  0.522104              0.509   \n",
       "3          0.650             0.302844  0.412402  0.542809              0.509   \n",
       "4          0.650             0.279016  0.419291  0.547286              0.509   \n",
       "...          ...                  ...       ...       ...                ...   \n",
       "34510      0.625             0.272098  0.450787  0.681589              1.000   \n",
       "34511      0.625             0.272098  0.450787  0.681589              1.000   \n",
       "34512      0.900             0.398924  0.481299  0.702854              1.000   \n",
       "34513      0.875             0.454266  0.804134  0.888640              1.000   \n",
       "34514      0.875             0.514220  0.575787  0.637941              1.000   \n",
       "\n",
       "       ...  Bleaching_Level_Population  Realm_Name_Central Indo-Pacific  \\\n",
       "0      ...                         0.0                              0.0   \n",
       "1      ...                         0.0                              0.0   \n",
       "2      ...                         0.0                              0.0   \n",
       "3      ...                         0.0                              0.0   \n",
       "4      ...                         0.0                              0.0   \n",
       "...    ...                         ...                              ...   \n",
       "34510  ...                         1.0                              0.0   \n",
       "34511  ...                         1.0                              0.0   \n",
       "34512  ...                         0.0                              0.0   \n",
       "34513  ...                         0.0                              0.0   \n",
       "34514  ...                         0.0                              0.0   \n",
       "\n",
       "       Realm_Name_Eastern Indo-Pacific  Realm_Name_Temperate Australasia  \\\n",
       "0                                  0.0                               0.0   \n",
       "1                                  1.0                               0.0   \n",
       "2                                  0.0                               0.0   \n",
       "3                                  0.0                               0.0   \n",
       "4                                  0.0                               0.0   \n",
       "...                                ...                               ...   \n",
       "34510                              0.0                               0.0   \n",
       "34511                              0.0                               0.0   \n",
       "34512                              0.0                               0.0   \n",
       "34513                              0.0                               0.0   \n",
       "34514                              0.0                               0.0   \n",
       "\n",
       "       Realm_Name_Temperate Northern Atlantic  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "...                                       ...   \n",
       "34510                                     0.0   \n",
       "34511                                     0.0   \n",
       "34512                                     0.0   \n",
       "34513                                     0.0   \n",
       "34514                                     0.0   \n",
       "\n",
       "       Realm_Name_Temperate Northern Pacific  Realm_Name_Tropical Atlantic  \\\n",
       "0                                        0.0                           1.0   \n",
       "1                                        0.0                           0.0   \n",
       "2                                        0.0                           1.0   \n",
       "3                                        0.0                           1.0   \n",
       "4                                        0.0                           1.0   \n",
       "...                                      ...                           ...   \n",
       "34510                                    0.0                           1.0   \n",
       "34511                                    0.0                           1.0   \n",
       "34512                                    0.0                           0.0   \n",
       "34513                                    0.0                           1.0   \n",
       "34514                                    0.0                           1.0   \n",
       "\n",
       "       Realm_Name_Tropical Eastern Pacific  Realm_Name_Western Indo-Pacific  \\\n",
       "0                                      0.0                              0.0   \n",
       "1                                      0.0                              0.0   \n",
       "2                                      0.0                              0.0   \n",
       "3                                      0.0                              0.0   \n",
       "4                                      0.0                              0.0   \n",
       "...                                    ...                              ...   \n",
       "34510                                  0.0                              0.0   \n",
       "34511                                  0.0                              0.0   \n",
       "34512                                  0.0                              1.0   \n",
       "34513                                  0.0                              0.0   \n",
       "34514                                  0.0                              0.0   \n",
       "\n",
       "       Exposure  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "34510         1  \n",
       "34511         1  \n",
       "34512         2  \n",
       "34513         0  \n",
       "34514         1  \n",
       "\n",
       "[34515 rows x 464 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "min_max_scaler=MinMaxScaler()\n",
    "df=pd.DataFrame(min_max_scaler.fit_transform(exp_less), columns=exp_less.columns)\n",
    "\n",
    "df=pd.concat([df, df_concatenated['Exposure']], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.reindex(columns=[col for col in df.columns if col != 'Exposure'] + ['Exposure'])\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoralExposureDataset(Dataset):\n",
    "    def __init__(self,data,transform=None):\n",
    "        super().__init__()\n",
    "        self.transform=transform\n",
    "        self.data=data\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row=self.data.iloc[idx]\n",
    "        feature = row[:-1].values.astype('float32')\n",
    "        target=row[-1]\n",
    "        if self.transform:\n",
    "            feature=self.transform(feature)\n",
    "        return torch.tensor(feature,dtype=torch.float32), torch.tensor(target,dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=CoralExposureDataset(df)\n",
    "\n",
    "train_size=int(0.8*len(dataset))\n",
    "test_size=len(dataset)-train_size\n",
    "\n",
    "train_data,test_data=torch.utils.data.random_split(dataset,[train_size,test_size])\n",
    "\n",
    "\n",
    "train_data_loader=DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_data_loader=DataLoader(test_data,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoralExposureClassifier(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(CoralExposureClassifier, self).__init__()\n",
    "        self.linear1=nn.Linear(input_dim,64)\n",
    "        self.batchnorm1=nn.BatchNorm1d(64)\n",
    "        self.linear2=nn.Linear(64,32)\n",
    "        self.batchnorm2=nn.BatchNorm1d(32)\n",
    "        self.linear3=nn.Linear(32,16)\n",
    "        self.batchnorm3=nn.BatchNorm1d(16)\n",
    "        self.linear4=nn.Linear(16,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.batchnorm1(self.linear1(x)))\n",
    "        x=F.relu(self.batchnorm2(self.linear2(x)))\n",
    "        x=F.relu(self.batchnorm3(self.linear3(x)))\n",
    "        x=self.linear4(x)\n",
    "        x=F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "input_dim=df.shape[1]-1\n",
    "output_dim=3\n",
    "model = CoralExposureClassifier(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3294585815.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  target=row[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.5714285969734192\n",
      "Epoch: 10 Loss: 0.5357142686843872\n",
      "Epoch: 20 Loss: 0.3571428656578064\n",
      "Epoch: 30 Loss: 0.5714285969734192\n",
      "Epoch: 40 Loss: 0.3928571343421936\n",
      "Epoch: 50 Loss: 0.5\n",
      "Epoch: 60 Loss: 0.4642857015132904\n"
     ]
    }
   ],
   "source": [
    "epoch_nums=70\n",
    "train_losses = []\n",
    "model.train()\n",
    "for epoch in range(epoch_nums):\n",
    "    total_train_loss = 0\n",
    "    for data,target in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=criterion(output,target.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_data_loader)\n",
    "    train_losses.append(avg_train_loss)    \n",
    "    if epoch%10==0:\n",
    "        print('Epoch:',epoch,'Loss:',loss.item())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3294585815.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  target=row[-1]\n",
      "/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4308071658015251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([23])) that is different to the input size (torch.Size([23, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_losses = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss=0\n",
    "    for i,(data,target) in enumerate(test_data_loader):\n",
    "        output=model(data)\n",
    "        loss=criterion(output,target)\n",
    "        total_loss += loss.item()\n",
    "    avg_val_loss=total_loss/len(test_data_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print('Validation Loss:',np.mean(val_losses))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-11 02:56:34,601] A new study created in memory with name: no-name-898cf924-2afe-49f3-a7e1-a91a365efb22\n",
      "/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3777389925.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3294585815.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  target=row[-1]\n",
      "[I 2024-07-11 03:08:58,319] Trial 0 finished with value: 0.8950258181602867 and parameters: {'hidden_dim1': 242, 'hidden_dim2': 63, 'lr': 0.0032446830711106898, 'batch_size': 44}. Best is trial 0 with value: 0.8950258181602867.\n",
      "[I 2024-07-11 03:20:15,850] Trial 1 finished with value: 1.179444003712248 and parameters: {'hidden_dim1': 244, 'hidden_dim2': 101, 'lr': 0.02708971805756758, 'batch_size': 20}. Best is trial 0 with value: 0.8950258181602867.\n",
      "[I 2024-07-11 03:31:53,534] Trial 2 finished with value: 0.7282506233012235 and parameters: {'hidden_dim1': 171, 'hidden_dim2': 105, 'lr': 0.006309289907589171, 'batch_size': 29}. Best is trial 2 with value: 0.7282506233012235.\n",
      "[I 2024-07-11 03:43:14,141] Trial 3 finished with value: 0.9351022542902717 and parameters: {'hidden_dim1': 84, 'hidden_dim2': 68, 'lr': 0.0009003569387638931, 'batch_size': 33}. Best is trial 2 with value: 0.7282506233012235.\n",
      "[I 2024-07-11 03:54:00,360] Trial 4 finished with value: 0.9827708924810091 and parameters: {'hidden_dim1': 179, 'hidden_dim2': 40, 'lr': 6.663215502767586e-05, 'batch_size': 88}. Best is trial 2 with value: 0.7282506233012235.\n",
      "[I 2024-07-11 04:04:46,741] Trial 5 finished with value: 1.7157269879071801 and parameters: {'hidden_dim1': 171, 'hidden_dim2': 45, 'lr': 0.004609626074360201, 'batch_size': 36}. Best is trial 2 with value: 0.7282506233012235.\n",
      "[I 2024-07-11 04:15:55,402] Trial 6 finished with value: 0.9889390308547903 and parameters: {'hidden_dim1': 196, 'hidden_dim2': 27, 'lr': 1.9614353111523723e-05, 'batch_size': 93}. Best is trial 2 with value: 0.7282506233012235.\n",
      "[W 2024-07-11 04:26:38,232] Trial 7 failed with parameters: {'hidden_dim1': 153, 'hidden_dim2': 85, 'lr': 4.0323423560375264e-05, 'batch_size': 22} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3777389925.py\", line 39, in objective\n",
      "    for feature, target in train_data_loader:\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in <listcomp>\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3294585815.py\", line 8, in __getitem__\n",
      "    row=self.data.iloc[idx]\n",
      "        ~~~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/indexing.py\", line 1191, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/indexing.py\", line 1754, in _getitem_axis\n",
      "    return self.obj._ixs(key, axis=axis)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/frame.py\", line 3984, in _ixs\n",
      "    new_mgr = self._mgr.fast_xs(i)\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/internals/managers.py\", line 1002, in fast_xs\n",
      "    result[rl] = blk.iget((i, loc))\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Mehr/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/internals/blocks.py\", line 1253, in iget\n",
      "    def iget(self, i: int | tuple[int, int] | tuple[slice, int]) -> np.ndarray:\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2024-07-11 04:26:38,243] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_val_loss\n\u001b[1;32m     64\u001b[0m study\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial params:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[206], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     38\u001b[0m     total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[199], line 8\u001b[0m, in \u001b[0;36mCoralExposureDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[0;32m----> 8\u001b[0m     row\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     feature \u001b[38;5;241m=\u001b[39m row[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     target\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/indexing.py:1754\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/frame.py:3984\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3984\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3986\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3987\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/internals/managers.py:1002\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(blk\u001b[38;5;241m.\u001b[39mmgr_locs):\n\u001b[0;32m-> 1002\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\n",
      "File \u001b[0;32m~/Desktop/Python/me/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1253\u001b[0m, in \u001b[0;36mBlock.iget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m-> 1253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miget\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;66;03m# In the case where we have a tuple[slice, int], the slice will always\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;66;03m#  be slice(None)\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;66;03m# Note: only reached with self.ndim == 2\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;66;03m# Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;66;03m# for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;66;03m# \"Union[int, integer[Any]]\"\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[i]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slice\u001b[39m(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mself\u001b[39m, slicer: \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]\n\u001b[1;32m   1264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "class CoralModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2):\n",
    "        super(CoralModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.linear3 = nn.Linear(hidden_dim2, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.linear1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.batchnorm2(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = df.shape[1] - 1\n",
    "    \n",
    "    hidden_dim1 = trial.suggest_int('hidden_dim1', 64, 256)\n",
    "    hidden_dim2 = trial.suggest_int('hidden_dim2', 16, 128)\n",
    "    \n",
    "    model = CoralModel(input_dim, hidden_dim1, hidden_dim2)\n",
    "    \n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128, log=True)\n",
    "    \n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    num_epochs=50\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        for feature, target in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feature)\n",
    "            loss = criterion(outputs, target.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_data_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for feature, target in test_data_loader:\n",
    "            outputs = model(feature)\n",
    "            loss = criterion(outputs, target.view(-1, 1))\n",
    "            total_loss += loss.item()\n",
    "        avg_val_loss = total_loss / len(test_data_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "    \n",
    "    return avg_val_loss\n",
    "\n",
    "\n",
    "study=optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective,n_trials=15)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial params:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/3kfwh15d7234657gp2jqxqj80000gn/T/ipykernel_15228/3294585815.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  target=row[-1]\n"
     ]
    }
   ],
   "source": [
    "dataset=CoralExposureDataset(df)\n",
    "\n",
    "train_size=int(0.8*len(dataset))\n",
    "test_size=len(dataset)-train_size\n",
    "\n",
    "train_data,test_data=torch.utils.data.random_split(dataset,[train_size,test_size])\n",
    "\n",
    "\n",
    "train_data_loader=DataLoader(train_data,batch_size=29,shuffle=True)\n",
    "test_data_loader=DataLoader(test_data,batch_size=29,shuffle=True)\n",
    "\n",
    "class CoralExposureClassifier(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(CoralExposureClassifier, self).__init__()\n",
    "        self.linear1=nn.Linear(input_dim,171)\n",
    "        self.batchnorm1=nn.BatchNorm1d(171)\n",
    "        self.linear2=nn.Linear(171,105)\n",
    "        self.batchnorm2=nn.BatchNorm1d(105)\n",
    "        self.linear3=nn.Linear(105,16)\n",
    "        self.batchnorm3=nn.BatchNorm1d(16)\n",
    "        self.linear4=nn.Linear(16,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.batchnorm1(self.linear1(x)))\n",
    "        x=F.relu(self.batchnorm2(self.linear2(x)))\n",
    "        x=F.relu(self.batchnorm3(self.linear3(x)))\n",
    "        x=self.linear4(x)\n",
    "        x=F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "input_dim=df.shape[1]-1\n",
    "output_dim=3\n",
    "model = CoralExposureClassifier(input_dim, output_dim)\n",
    "\n",
    "#[I 2024-07-11 03:31:53,534] Trial 2 finished with value: 0.7282506233012235 and parameters: {'hidden_dim1': 171, 'hidden_dim2': 105, 'lr': 0.006309289907589171, 'batch_size': 29}. Best is trial 2 with value: 0.7282506233012235.\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.006309289907589171)\n",
    "criterion=nn.MSELoss()\n",
    "epoch_nums=70\n",
    "train_losses = []\n",
    "model.train()\n",
    "for epoch in range(epoch_nums):\n",
    "    total_train_loss = 0\n",
    "    for data,target in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=criterion(output,target.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_data_loader)\n",
    "    train_losses.append(avg_train_loss)    \n",
    "    if epoch%10==0:\n",
    "        print('Epoch:',epoch,'Loss:',loss.item())\n",
    "\n",
    "\n",
    "\n",
    "val_losses = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss=0\n",
    "    for i,(data,target) in enumerate(test_data_loader):\n",
    "        output=model(data)\n",
    "        loss=criterion(output,target)\n",
    "        total_loss += loss.item()\n",
    "    avg_val_loss=total_loss/len(test_data_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print('Validation Loss:',np.mean(val_losses))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'coral_model.pth')\n",
    "\n",
    "\n",
    "input_dim = df.shape[1] - 1\n",
    "hidden_dim1 = study.best_trial.params['hidden_dim1']\n",
    "hidden_dim2 = study.best_trial.params['hidden_dim2']\n",
    "model = CoralModel(input_dim, hidden_dim1, hidden_dim2)\n",
    "model.load_state_dict(torch.load('coral_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
